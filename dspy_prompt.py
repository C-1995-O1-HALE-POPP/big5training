import dspy
from dspy import Signature, InputField, OutputField
import numpy as np
import os
from typing import Dict
from loguru import logger
from Big5StabilityExperiment.ocean_classifier.inference import big5_classifier
import sys
import json
from utils.inference_lora import LoRAInference
from utils.prompt import generate_system_prompt, DEFAULT_QUESTION
# ----------------------------
# æ—¥å¿—é…ç½®
# ----------------------------
logger.remove()
logger.add(
    sink=sys.stderr,
    level="INFO",
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
           "<level>{level: <8}</level> | "
           "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
           "<level>{message}</level>"
)
logger.add(
    sink="logs/dspy_prompt.log",
    level="INFO",
    rotation="1 day",
    retention="7 days",
    compression="zip",
    encoding="utf-8",
    format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {message}"
)

inference = LoRAInference()

LORAS_HI_DIR = {
    "O": "output_lora_O_high",
    "C": "output_lora_C_high",
    "E": "output_lora_E_high",
    "A": "output_lora_A_high",
    "N": "output_lora_N_high"
}

LORAS_LO_DIR = {
    "O": "output_lora_O_low",
    "C": "output_lora_C_low",
    "E": "output_lora_E_low",
    "A": "output_lora_A_low",
    "N": "output_lora_N_low"
}
# ----------------------------
# Classifier åŠ è½½
# ----------------------------
CLASSIFIER_DIR = "Big5StabilityExperiment/ocean_classifier"
classifier = big5_classifier(model_root=CLASSIFIER_DIR)

# ----------------------------
# å‚æ•°é…ç½®
# ----------------------------
QUESTION = DEFAULT_QUESTION
N_SAMPLES = 20
TARGET_STD = 0.3
MAX_ROUNDS = 100

# ----------------------------
# åŠ è½½å¤§æ¨¡å‹ï¼ˆå¯æ¢æˆä½ è‡ªå·±çš„ï¼‰
# ----------------------------
API_KEY = os.getenv("DASHSCOPE_API_KEY")
API_BASE = "https://dashscope.aliyuncs.com/compatible-mode/v1"
MODEL_NAME = "openai/qwen3-8b"

# é…ç½® DSPy ä½¿ç”¨è¯¥æ¨¡å‹
lm = dspy.LM(
    model=MODEL_NAME,
    api_base=API_BASE,
    api_key=API_KEY,
    temperature=0.8,
    top_p=0.9,
    max_tokens=256,
    do_sample=True,
    extra_body={"enable_thinking": False}
)
dspy.settings.configure(lm=lm, cache=False)

# ----------------------------
# DSPy æ¨¡å—å®šä¹‰
# ----------------------------

class PromptGenerator(Signature):
    trait = InputField(desc="Big Five trait to simulate")
    level = InputField(desc="Target trait level between 0 and 1")
    feedback = InputField(desc="Previous round feedback for improving the prompt", default="")
    prompt = OutputField(desc="System prompt that reflects the personality")

generate_prompt = dspy.ChainOfThought(PromptGenerator)

class PersonalityResponder(Signature):
    context = InputField(desc="System prompt representing personality")
    question = InputField(desc="Input question")
    answer = OutputField(desc="Model answer reflecting the personality")

responder = dspy.ChainOfThought(PersonalityResponder)

class SelfCritique(Signature):
    trait = InputField()
    target_level = InputField()
    prompt = InputField()
    hi_ratio = InputField()
    feedback = OutputField()

critic = dspy.ChainOfThought(SelfCritique)

# ----------------------------
# Prompt æµ‹è¯•ä¸è¯„åˆ†å‡½æ•°
# ----------------------------
def evaluate_prompt(prompt: str, trait: str, target_level: float) -> Dict:
    """ç»™å®š promptï¼Œæµ‹è¯• N_SAMPLES æ¬¡æ¨¡å‹å›ç­”ï¼Œç”¨ big5_classifier æ‰“åˆ†"""
    answers = []
    labels = []
    
    for _ in range(N_SAMPLES):
        reply = inference.generate(prompt, QUESTION)
        logger.info(f"Model reply: {reply}")
        label = classifier.inference([reply])[0][trait]["label"]
        answers.append(label)
        labels.append(1 if label == 'high' else 0)  # è½¬æ¢ä¸º 0/1 è®¡ç®— std
    hi_ratio = sum(labels) / len(labels)
    std_dev = np.std(labels)

    return {
        "prompt": prompt,
        "hi_ratio": hi_ratio,
        "diff": abs(hi_ratio - target_level),
        "std": std_dev,
        "answers": answers,
    }

# ----------------------------
# ä¸»ä¼˜åŒ–å‡½æ•°
# ----------------------------
def optimize_prompt(trait: str, level: float, max_rounds: int = MAX_ROUNDS) -> Dict:
    history = []
    feedback = ""  # åˆå§‹æ— åé¦ˆ
    lora_dirs = LORAS_HI_DIR if level > 0.5 else LORAS_LO_DIR
    inference.load_lora(lora_dirs[trait[0].upper()])  # æ ¹æ® trait åŠ è½½å¯¹åº” LoRA
    for i in range(max_rounds):
        logger.info(f"\nğŸ” Round {i + 1} / {max_rounds}\n")

        # ç”¨åé¦ˆç”Ÿæˆæ–°çš„ prompt
        prompt = generate_prompt(trait=trait, level=level, feedback=feedback).prompt

        logger.info(f"ğŸ“ Prompt:\n{prompt}\n")
        result = evaluate_prompt(prompt, trait, level)
        logger.info(f"ğŸ“Š hi_ratio={result['hi_ratio']:.2f}, target={level:.2f}, std={result['std']:.3f}")

        history.append(result)

        # åˆ¤æ–­æ˜¯å¦æ”¶æ•›
        if abs(result['hi_ratio'] - level) <= 0.1 and result['std'] <= TARGET_STD:
            logger.success("âœ… Converged!")
            inference.unload() 
            return result

        # ä»æœ¬è½®ç»“æœç”Ÿæˆåé¦ˆ
        suggestion = critic(trait=trait, target_level=level, prompt=prompt, hi_ratio=result['hi_ratio'])
        feedback = suggestion.feedback.strip()  # æ›´æ–° feedback ä»¥ä¾›ä¸‹ä¸€è½®ä½¿ç”¨
    inference.unload()  # é‡Šæ”¾ LoRA æ¨¡å‹
    logger.warning("âš ï¸ Did not converge. Returning best result.")
    return sorted(history, key=lambda x: x['diff'])[0]
# ----------------------------
# ç¤ºä¾‹è°ƒç”¨
# ----------------------------
if __name__ == "__main__":
    inference.load_lora(lora_dir=None)  # å¯æ›´æ¢ä¸ºä»»æ„ LoRA adapter è·¯å¾„
    trait = "extraversion"
    level = 0.3
    final_result = optimize_prompt(trait, level)

    logger.info("\nğŸ”¥ æœ€ç»ˆæ”¶æ•› promptï¼š")
    logger.info(final_result["prompt"])
    logger.success(f"âœ… hi_ratio: {final_result['hi_ratio']}")
